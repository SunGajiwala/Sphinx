{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465620b9-b408-4449-91b8-2fc918a92a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import ADMSMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c843b81-2a62-438c-a5b3-6211f13bd484",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844fc270-a915-4656-bc63-b1d2730c4094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding..\n",
      "Training model for 12 features for ms_data_science\n",
      "Accuracy score: 79.553 %\n",
      "Feature importances saved to model/saved/ms_data_science_model_feature_imp.csv\n",
      "Feature importance:                           Features  Importance\n",
      "0      School GPA (Recalculated)_1    0.212272\n",
      "1                School Backlogs_1    0.120675\n",
      "2           Total_experience_years    0.067139\n",
      "3   latest_school_duration_in_year    0.056480\n",
      "4              School_Gap_in_Years    0.043950\n",
      "5                 GRE Quantitative    0.035633\n",
      "6     Converted English Prof Score    0.035418\n",
      "7                       GRE Verbal    0.024328\n",
      "8          School Major Category_1    0.019407\n",
      "9                Gap_from_last_job    0.016806\n",
      "10          GRE Analytical Writing    0.015152\n",
      "11         Standardized test given    0.000000\n",
      "Saved trained model for ms_data_science at model/saved/ms_data_science_finalized_model.sav.\n"
     ]
    }
   ],
   "source": [
    "clf = ADMSMClassifier(training_file_path='../data/Merged_Data_2023-04-26_18-47-22.csv', config_filepath='config.yml')\n",
    "model_ds = clf.load_or_train_model(retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e8767b-f427-45d2-8f66-31fcc92e0201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding..\n",
      "Training model for 12 features for ms_engineering_om\n",
      "Accuracy score: 93.103 %\n",
      "Feature importances saved to model/saved/ms_engineering_om_model_feature_imp.csv\n",
      "Feature importance:                           Features  Importance\n",
      "0                School Backlogs_1    0.089455\n",
      "1      School GPA (Recalculated)_1    0.046759\n",
      "2              School_Gap_in_Years    0.025065\n",
      "3     Converted English Prof Score    0.012360\n",
      "4   latest_school_duration_in_year    0.011668\n",
      "5                       GRE Verbal    0.008211\n",
      "6           Total_experience_years    0.008124\n",
      "7                Gap_from_last_job    0.005791\n",
      "8          School Major Category_1    0.000605\n",
      "9                 GRE Quantitative    0.000432\n",
      "10          GRE Analytical Writing    0.000000\n",
      "11         Standardized test given    0.000000\n",
      "Saved trained model for ms_engineering_om at model/saved/ms_engineering_om_finalized_model.sav.\n"
     ]
    }
   ],
   "source": [
    "clf = ADMSMClassifier(study_area=\"ms_engineering_om\", training_file_path='../data/Merged_Data_2023-04-26_18-47-22.csv', config_filepath='config.yml')\n",
    "model_eom = clf.load_or_train_model(retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036a8b25-2116-4444-843b-82e02638f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample test data\n",
    "clf.df.shape\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = clf.df.drop(\"Decision Name\", axis=1)\n",
    "y = clf.df[\"Decision Name\"]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=7\n",
    ")\n",
    "\n",
    "X_test.to_csv(\"../data/Sample_X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c67f65-38b7-442f-a3b6-913ba1259280",
   "metadata": {},
   "source": [
    "## Model Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3daba82f-4be6-47d7-bee2-66b45dc39f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding..\n",
      "Note: model_output=='probability'. For HistGradientBoostingClassifier shap values normally get calculated against X_background, but paramater X_background=None, so using X instead\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model, X, model_output='probability', feature_perturbation='interventional')...\n",
      "Note: Shap interaction values will not be available. If shap values in probability space are not necessary you can pass model_output='logodds' to get shap values in logodds without the need for a background dataset and also working shap interaction values...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=1164) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.9.2) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "For this type of model and model_output interactions don't work, so setting shap_interaction=False...\n",
      "The explainer object has no decision_trees property. so setting decision_trees=False...\n",
      "Generating layout...\n",
      "Calculating shap values...\n",
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n",
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
      "Calculating predictions...\n",
      "Calculating pred_percentiles...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Label Encoding..\n",
      "Note: model_output=='probability'. For HistGradientBoostingClassifier shap values normally get calculated against X_background, but paramater X_background=None, so using X instead\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model, X, model_output='probability', feature_perturbation='interventional')...\n",
      "Note: Shap interaction values will not be available. If shap values in probability space are not necessary you can pass model_output='logodds' to get shap values in logodds without the need for a background dataset and also working shap interaction values...\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "For this type of model and model_output interactions don't work, so setting shap_interaction=False...\n",
      "The explainer object has no decision_trees property. so setting decision_trees=False...\n",
      "Generating layout...\n",
      "Calculating shap values...\n",
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n",
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
      "Calculating predictions...\n",
      "Calculating pred_percentiles...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "from util import ADMSMClassifier\n",
    "\n",
    "study_areas = [\"ms_data_science\", \"ms_engineering_om\"]\n",
    "\n",
    "# load model\n",
    "def run_explainer(clf, study_area_idx):\n",
    "    # Get sample test data\n",
    "\n",
    "#     df = clf.load_and_preprocess_data()\n",
    "#     X = df.drop(\"Decision Name\", axis=1)\n",
    "#     y = df[\"Decision Name\"]\n",
    "\n",
    "#     # scaler = StandardScaler()\n",
    "#     # X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.20, random_state=7\n",
    "#     )\n",
    "\n",
    "    model = clf.load_model()\n",
    "    explainer = ClassifierExplainer(model, X_test, y_test)\n",
    "\n",
    "    ExplainerDashboard(explainer).save_html(f'saved/explainer_model_{study_areas[study_area_idx]}.html')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # data science\n",
    "    clf = ADMSMClassifier(study_area=study_areas[0], config_filepath = 'config.yml')\n",
    "    run_explainer(clf, study_area_idx = 0)\n",
    "    # Eom\n",
    "    clf = ADMSMClassifier(study_area=study_areas[1], config_filepath = 'config.yml')\n",
    "    run_explainer(clf, study_area_idx = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03f59f-38a3-4a49-8c9e-6ba710b7b68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
